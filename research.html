<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="mystyle.css">
    <meta charset="utf-8">
    <title>Daniel S.H. Kao</title>
    <link rel = "icon" href = "src/icon.png"
        type = "image/x-icon">
  </head>
  <body>
    <div>
        <center><table style="width:100%" id="bookmark">
            <colgroup>
                <col span="1" style="width: 52%;">
                <col span="1" style="width: 12%;">
                <col span="1" style="width: 12%;">
                <col span="1" style="width: 12%;">
                <col span="1" style="width: 12%;">
            </colgroup>
            <tr>
                <th ><div id="header">
                    <h1>Daniel Shiu-hong Kao 高旭宏</h1>
                </div></th>
                <th ><a id="bookmark_home" href="./index.html"><h3><u>Home</u></h3></a></th>
                <th ><h3 id="bookmark_research">Research</h3></th>
                <th ><a id="bookmark_exp" href="./experience.html"><h3><u>Experiences</u></h3></a></th>
                <th ><a id="bookmark_award" href="./award.html"><h3><u>Awards</u></h3></a></th>
                </tr>
        </table></center>
    </div>
    
    <div id="Research" class="section">
        <h2>Publications:</h2>
            <table id="pub_table" style="width:100%">
                <tr>
                    <td class="pub_left">
                        <div class='one'><center><img class="pub_img" src="src/dnd.png"/></center></div>
                    </td>
                    <td class="pub_right">
                        <b>Divide and Distill: Achieving Higher Accuracy, Speed and Data-Efficiency for Knowledge Distillation</b><br/>
                        Anonymous<br/>
                        <i>Coming soon!</i><br/>
                        <p>We propose a fast, accurate, and data-efficient technique for neural network compression that can be applied on multiple CNN and vision transformer models.</p>
                    </td>
                </tr>
                <tr>
                    <td class="pub_left">
                        <div class='one'><center><img class="pub_img" src="src/deceptive-nerf.png"/></center></div>
                    </td>
                    <td class="pub_right">
                        <b>Deceptive-NeRF: Enhancing NeRF Reconstruction using Pseudo-Observations from Diffusion Models</b><br/>
                        Xinhang Liu, <u>Shiu-hong Kao</u>, Jiaben Chen, Yu-Wing Tai, Chi-Keung Tang<br/>
                        <i>Under review. Code released soon.</i><br/>
                        [<a href="https://arxiv.org/abs/2305.15171" target="_blank">arXiv</a>]<br/>
                        <p>We introduce Deceptive-NeRF, a new method for enhancing the quality of reconstructed NeRF models using synthetically generated pseudo-observations, capable of handling sparse input and removing floater artifacts.</p>
                    </td>
                </tr>
                <tr>
                    <td class="pub_left">
                        <div class='one'><center><img class="pub_img" src="src/pconv.png"/></center></div>
                    </td>
                    <td class="pub_right">
                        <b>Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks</b><br/>
                        Jierun Chen, <u>Shiu-hong Kao</u>, Hao He, Weipeng Zhuo, Song Wen, Chul-Ho Lee, S.-H. Gary Chan<br/>
                        <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</i><br/>
                        [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Run_Dont_Walk_Chasing_Higher_FLOPS_for_Faster_Neural_Networks_CVPR_2023_paper.html" target="_blank">Paper</a>]
                        [<a href="https://arxiv.org/abs/2303.03667" target="_blank">arXiv</a>]
                        [<a href="https://github.com/JierunChen/FasterNet" target="_blank">code</a>]<br/>
                        <p>We propose a simple yet fast and effective partial convolution (PConv), as well as a latency-efficient family of network architectures called FasterNet.</p>
                    </td>
                </tr>
                <tr>
                    <td class="pub_left">
                        <div class='one'><center><img class="pub_img" src="src/int partition.png"/></center></div>
                    </td>
                    <td class="pub_right">
                        <b>Integer Partition: Further Discussion of the Number of the Integer-side Triangles</b><br/>
                        <u>Shiu-hong Kao</u>, Pohsing Chou, Gerard Jennhwa Chang<br/>
                        <i>Yau's Award, National Taiwan University, 2018</i><br/>
                        [<a href="http://www.math.ntu.edu.tw/~shing_tung/PDF/10th/Kao_1.pdf" target="_blank">Original paper</a>]
                        [<a href="src/Yau's award paper.pdf" target="_blank">English version</a>]<br/>
                        <p>We prove the number of integer-side triangles/quadrilaterals with fixed perimeters in two different ways and deduce a recursive relaitonship for n-sided polygons.</p>
                    </td>
                    </tr>
            </table>
            <h2>Projects:</h2>
            <ul>
                <li>
                    <b>Dynamic Neural Network Comparison: Efficiency and Performance</b><br/>
                    <u>Shiu-hong Kao</u>, Jierun Chen, S.-H. Gary Chan<br/>
                    <i>Undergraduate Research Opportunities Program, Fall 2021, HKUST</i><br/>
                    [<a href="src/dnn report.pdf" target="_blank">pdf</a>]<br/>
                    <p>We test, analyze, and compare the performance and efficiency across different deep learning models.</p>
                </li><br/>
                <li>
                    <b>Press Release Classification on Mobile Application</b><br/>
                    <u>Shiu-hong Kao</u>, Dimitris Chatzopoulos<br/>
                    <i>Undergraduate Research Opportunities Program, Spring 2021, HKUST</i><br/>
                    [<a href="src/android report.pdf" target="_blank">pdf</a>]<br/>
                    <p>We develope a text-classifying AI model compact with memory-limited mobile devices.</p>
                </li><br/>
                <li>
                    <b>AlignKD: A Low-cost Technique for Convolutional Shortcut Removal</b><br/>
                    <u>Shiu-hong Kao</u>, Bo-rong Lai<br/>
                    <i>Course project for COMP4471 Deep Learning in Computer Vision, HKUST</i><br/>
                    [<a href="src/AlignKD.pdf" target="_blank">pdf</a>]<br/>
                    <p>AlignKD is a cheap method to remove shortcuts in convolutional neural networks while preserving the performance.</p>
                </li>
            </ul>
    </div>
    <div id="footer">
        <hr/>
            <center><small style="color: rgb(160, 160, 160)">© Daniel Kao | Last updated: May. 2023.</small></center>
        
    </div>
  </body>
</html>